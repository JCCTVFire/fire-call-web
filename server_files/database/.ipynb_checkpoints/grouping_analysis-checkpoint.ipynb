{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form endoints for table requests\n",
    "endpoint = 'http://localhost:3000/api'\n",
    "incidents_end, calls_end, dispatch_end = endpoint + '/incidents', endpoint + '/calls', endpoint + '/dispatch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9210 entries, 0 to 9209\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   incident_id    9210 non-null   int64 \n",
      " 1   date           9210 non-null   object\n",
      " 2   description    9210 non-null   object\n",
      " 3   postal_code    9210 non-null   object\n",
      " 4   district_code  9210 non-null   object\n",
      " 5   call_id        0 non-null      object\n",
      " 6   dispatch_id    0 non-null      object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 503.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get incidents table data\n",
    "incidents_res = requests.get(incidents_end)\n",
    "incidents_raw = incidents_res.json()\n",
    "incidents = incidents_raw['data']\n",
    "i_df = pd.DataFrame.from_records(incidents)\n",
    "i_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9210 entries, 0 to 9209\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   call_id     9210 non-null   int64 \n",
      " 1   call_type   9210 non-null   object\n",
      " 2   call_class  9210 non-null   object\n",
      " 3   call_time   9210 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 287.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get calls table data\n",
    "calls_res = requests.get(calls_end)\n",
    "calls_raw = calls_res.json()\n",
    "calls = calls_raw['data']\n",
    "c_df = pd.DataFrame.from_records(calls)\n",
    "c_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9210 entries, 0 to 9209\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   dispatch_id    9210 non-null   int64 \n",
      " 1   dispatch_time  9210 non-null   object\n",
      " 2   arrival_time   9210 non-null   object\n",
      " 3   response_time  9210 non-null   object\n",
      " 4   arrival_unit   9210 non-null   object\n",
      " 5   cleared_time   9210 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 431.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Get dispatch table data\n",
    "dispatch_res = requests.get(dispatch_end)\n",
    "dispatch_raw = dispatch_res.json()\n",
    "dispatch = dispatch_raw['data']\n",
    "d_df = pd.DataFrame.from_records(dispatch)\n",
    "d_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   incident_id        date                                       description  \\\n",
      "0      1800001  2018-01-01  EMS call, excluding vehicle accident with injury   \n",
      "1      1800002  2018-01-01              Motor vehicle accident with injuries   \n",
      "2      1800005  2018-01-01                                    Public service   \n",
      "3      1800007  2018-01-01  EMS call, excluding vehicle accident with injury   \n",
      "4      1800009  2018-01-01  EMS call, excluding vehicle accident with injury   \n",
      "\n",
      "  postal_code district_code  \n",
      "0   22201          10410     \n",
      "1   20301          10121     \n",
      "2   20301          10124     \n",
      "3   22202          10505     \n",
      "4   22201          10409     \n",
      "0          0\n",
      "1          1\n",
      "2          2\n",
      "3          3\n",
      "4          4\n",
      "        ... \n",
      "9205    9205\n",
      "9206    9206\n",
      "9207    9207\n",
      "9208    9208\n",
      "9209    9209\n",
      "Name: a, Length: 9210, dtype: int64 0          0\n",
      "1          1\n",
      "2          2\n",
      "3          3\n",
      "4          4\n",
      "        ... \n",
      "9205    9205\n",
      "9206    9206\n",
      "9207    9207\n",
      "9208    9208\n",
      "9209    9209\n",
      "Name: a, Length: 9210, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9210 entries, 0 to 9209\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   incident_id    9210 non-null   int64 \n",
      " 1   date           9210 non-null   object\n",
      " 2   description    9210 non-null   object\n",
      " 3   postal_code    9210 non-null   object\n",
      " 4   district_code  9210 non-null   object\n",
      " 5   a              9210 non-null   int64 \n",
      " 6   dispatch_id    9210 non-null   int64 \n",
      " 7   dispatch_time  9210 non-null   object\n",
      " 8   arrival_time   9210 non-null   object\n",
      " 9   response_time  9210 non-null   object\n",
      " 10  arrival_unit   9210 non-null   object\n",
      " 11  cleared_time   9210 non-null   object\n",
      " 12  call_id        9210 non-null   int64 \n",
      " 13  call_type      9210 non-null   object\n",
      " 14  call_class     9210 non-null   object\n",
      " 15  call_time      9210 non-null   object\n",
      "dtypes: int64(4), object(12)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "i_df1 = i_df.iloc[:,:5]\n",
    "print(i_df1.head())\n",
    "d_df['a'] = [x for x in range(len(i_df1.incident_id))]\n",
    "i_df1['a'] = [x for x in range(len(i_df1.incident_id))]\n",
    "print(d_df['a'], i_df1['a'])\n",
    "joined = i_df1.merge(d_df, left_on = 'a', right_on = 'a')\n",
    "c_df['a'] = [x for x in range(len(i_df1.incident_id))]\n",
    "joined1 = joined.merge(c_df, left_on = 'a', right_on = 'a')\n",
    "joined1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9210 entries, 0 to 9209\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           9210 non-null   object \n",
      " 1   postal_code    9210 non-null   object \n",
      " 2   district_code  9210 non-null   object \n",
      " 3   dispatch_time  9210 non-null   float64\n",
      " 4   arrival_time   9210 non-null   float64\n",
      " 5   response_time  9210 non-null   object \n",
      " 6   arrival_unit   9210 non-null   object \n",
      " 7   cleared_time   9210 non-null   float64\n",
      " 8   call_type      9210 non-null   object \n",
      " 9   call_class     9210 non-null   object \n",
      " 10  call_time      9210 non-null   float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 863.4+ KB\n",
      "         date postal_code district_code  dispatch_time  arrival_time  \\\n",
      "0  2018-01-01   22201          10410          9.966667     15.666667   \n",
      "1  2018-01-01   20301          10121         14.333333     19.666667   \n",
      "2  2018-01-01   20301          10124         23.833333     31.116667   \n",
      "3  2018-01-01   22202          10505         80.266667     86.650000   \n",
      "4  2018-01-01   22201          10409         86.050000     94.500000   \n",
      "\n",
      "  response_time arrival_unit  cleared_time call_type call_class  call_time  \n",
      "0         6.030        M102      27.633333    INJURY    Medical   9.633333  \n",
      "1         6.920        M101      83.266667      SICK    Medical  12.750000  \n",
      "2        10.480        M109      34.583333    INVEST       Fire  20.633333  \n",
      "3         6.770        M105      97.150000      SICK    Medical  79.883333  \n",
      "4         8.730        M104      98.633333    INJURY    Medical  85.766667  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9210 entries, 0 to 9209\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   postal_code    7663 non-null   float64\n",
      " 1   dispatch_time  9210 non-null   float64\n",
      " 2   cleared_time   9210 non-null   float64\n",
      " 3   response_time  9210 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 359.8 KB\n"
     ]
    }
   ],
   "source": [
    "# [1,3,4,7,8,9,10,11,13,14,15]\n",
    "def mergeDateTime(date_str, time_str, time_var_name):\n",
    "    date_time_strs = date_str + ' ' + time_str\n",
    "    date = pd.to_datetime('2018-01-01' + ' 00:00:00', format='%Y-%m-%d %H:%M:%S')\n",
    "    date_time = pd.to_datetime(date_time_strs, format='%Y-%m-%d %H:%M:%S')\n",
    "    delta_minutes = pd.to_numeric(date_time - date)/(10**9)/60\n",
    "    return delta_minutes\n",
    "joined_slim = joined1.loc[:, ['date', 'postal_code', 'district_code', 'dispatch_time', 'arrival_time', 'response_time', 'arrival_unit', 'cleared_time', 'call_type', 'call_class', 'call_time']]\n",
    "joined_slim['dispatch_time'] = mergeDateTime(joined_slim['date'], joined_slim['dispatch_time'], 'dispatch_time')\n",
    "joined_slim['arrival_time'] = mergeDateTime(joined_slim['date'], joined_slim['arrival_time'], 'arrival_time')\n",
    "joined_slim['cleared_time'] = mergeDateTime(joined_slim['date'], joined_slim['cleared_time'], 'cleared_time')\n",
    "joined_slim['call_time'] = mergeDateTime(joined_slim['date'], joined_slim['call_time'], 'call_time')\n",
    "\n",
    "joined_slim.info()\n",
    "print(joined_slim.head())\n",
    "joined_slim['response_time'] = pd.to_numeric(joined_slim['response_time'])\n",
    "for x in joined_slim['postal_code']:\n",
    "    if x == '':\n",
    "        x = '0.000'\n",
    "joined_slim['postal_code'] = pd.to_numeric(joined_slim['postal_code'])\n",
    "\n",
    "joined_slim = joined_slim.loc[:, ['postal_code', 'dispatch_time', 'cleared_time', 'response_time']]\n",
    "joined_dummy = pd.get_dummies(joined_slim)\n",
    "joined_dummy.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a15b4ff34914>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mkm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mkm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoined_dummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mSum_of_squared_distances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    989\u001b[0m             )\n\u001b[0;32m    990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 991\u001b[1;33m         X = self._validate_data(X, accept_sparse='csr',\n\u001b[0m\u001b[0;32m    992\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m                                 \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    646\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     96\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "Sum_of_squared_distances = []\n",
    "K = [5, 10, 50]#, 100, 500, 1000]\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters = k)\n",
    "    km = km.fit(joined_dummy)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "    print(k)\n",
    "\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_of_squared_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_len = range(0,10000)\n",
    "for n in number_len: \n",
    "    num1 = random.uniform(38.845323,38.891033)\n",
    "    num2 = random.uniform(-77.065005,-77.113044)\n",
    "    x_coord.append(num1)\n",
    "    y_coord.append(num2)\n",
    "\n",
    "headers = ['lat', 'long']\n",
    "lat_long_df = pd.DataFrame({'lat': x_coord, 'long': y_coord}, columns = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_df.to_csv(\"longlat.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
